{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ad7c06-c6a9-475b-93bc-7e896470133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"Unet\"\n",
    "encoder = \"mobilenet_v2\"\n",
    "pretrain = \"imagenet\"\n",
    "inno = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff8e091-b02d-4cc8-ac80-0ba228bfb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    import torch\n",
    "    import segmentation_models_pytorch as smp\n",
    "    import torchvision\n",
    "    from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe2f603-8234-4a62-b08a-24769dc3d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "    net1 = getattr(smp, network)(\n",
    "        encoder_name= encoder,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=pretrain,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=inno,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=1,                      # model output channels (number of classes in your dataset)\n",
    "    ) \n",
    "   # net.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1367bb-91ea-4561-8811-77de629287a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): MobileNetV2Encoder(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1376, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(288, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac7fcc3-2b09-45ce-a94a-722f69140b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# child_counter = 0\n",
    "# for child in net.children():\n",
    "#    print(\" child\", child_counter, \"is:\")\n",
    "#    print(child)\n",
    "#    child_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021a5f24-54b8-45b2-98d4-1a129094887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.fc2 = nn.Linear(128, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158c1d59-cf96-4d10-8d10-d0d84c2404d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = nn.Sequential(*list(net.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2024691b-71d4-4238-bd48-1632d25b6d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43f8ecf-33d7-4923-8ec8-6e6b26082b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class unetver2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(unetver2, self).__init__()\n",
    "#         self.model =  net\n",
    "#         self.classifier_layer = nn.Sequential(\n",
    "#             nn.Linear(256*256 , 256*256),\n",
    "#            # nn.BatchNorm1d(512),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(256*256 , 256*256),\n",
    "#             #nn.Linear(256 ,1)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd3a58b-2d64-42a0-81a1-0520630c0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports first\n",
    "import torch.nn as nn\n",
    "\n",
    "# New models are defined as classes. Then, when we want to create a model we create an object instantiating this class.\n",
    "class Unet_FCL(nn.Module):\n",
    "    def __init__(self,LOAD_VIS_URL=None):\n",
    "        super(Unet_FCL, self).__init__()\n",
    "    \n",
    "         # Start with half the resnet model, swap out the final layer because that's the model we had defined above. \n",
    "        model = net1\n",
    "       # num_final_in = model.fc.in_features\n",
    "       # model.fc = nn.Linear(num_final_in, 300)\n",
    "        \n",
    "        # Now that the architecture is defined same as above, let's load the model we would have trained above. \n",
    "       # checkpoint = torch.load(MODEL_PATH)\n",
    "       # model.load_state_dict(checkpoint)\n",
    "        \n",
    "        \n",
    "#         # Let's freeze the same as above. Same code as above without the print statements\n",
    "#         child_counter = 0\n",
    "#         for child in model.children():\n",
    "#             if child_counter < 6:\n",
    "#                 for param in child.parameters():\n",
    "#                     param.requires_grad = False\n",
    "#             elif child_counter == 6:\n",
    "#                 children_of_child_counter = 0\n",
    "#                 for children_of_child in child.children():\n",
    "#                     if children_of_child_counter < 1:\n",
    "#                         for param in children_of_child.parameters():\n",
    "#                             param.requires_grad = False\n",
    "#                     else:\n",
    "#                     children_of_child_counter += 1\n",
    "\n",
    "#             else:\n",
    "#                 print(\"child \",child_counter,\" was not frozen\")\n",
    "#             child_counter += 1\n",
    "        \n",
    "        # Now, let's define new layers that we want to add on top. \n",
    "        # Basically, these are just objects we define here. The \"adding on top\" is defined by the forward()\n",
    "        # function which decides the flow of the input data into the model.\n",
    "        \n",
    "        # NOTE - Even the above model needs to be passed to self.\n",
    "        self.initmodel = nn.Sequential(*list(model.children()))\n",
    "        self.check_input_shape(x)\n",
    "\n",
    "        features = self.encoder(x)\n",
    "        decoder_output = self.decoder(*features)\n",
    "\n",
    "        masks = self.segmentation_head(decoder_output)\n",
    "\n",
    "        if self.classification_head is not None:\n",
    "            labels = self.classification_head(features[-1])\n",
    "            return masks, labels\n",
    "\n",
    "        return masks\n",
    "       # self.projective = nn.Linear(256*256,256*256)\n",
    "       # self.nonlinearity = nn.ReLU(inplace=True)\n",
    "       # self.projective2 = nn.Linear(256*256,256*256)\n",
    "        \n",
    "    \n",
    "    # The forward function defines the flow of the input data and thus decides which layer/chunk goes on top of what.\n",
    "    def forward(self,x):\n",
    "        x = self.initmodel(x)\n",
    "      #  x = torch.squeeze(x)\n",
    "        #x = self.projective(x)\n",
    "       # x = self.nonlinearity(x)\n",
    "      #  x = self.projective2(x)\n",
    "        # x = self.dense\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cfb5176-6cff-4c65-b12f-488f83c8169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Some imports first\n",
    "import torch.nn as nn\n",
    "\n",
    "# New models are defined as classes. Then, when we want to create a model we create an object instantiating this class.\n",
    "class Unet_FCLtest(nn.Module):\n",
    "    \n",
    "  def __init__(self):\n",
    "        super(Unet_FCLtest, self).__init__()\n",
    "        net1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=8, kernel_size=5),    # no padding, stride=1, dilation=1 by default\n",
    "            # Hout = Hin +1 - kernelsize\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Hout = (Hin -2)/2 + 1\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256,256),     # with 32x32 input, the feature map size reduces to 5x5 with 16 channels.\n",
    "            nn.Linear(256,400),\n",
    "            nn.Linear(400,64*64), \n",
    "           # nn.Linear(128*128,256*256), \n",
    "           # nn.Unflatten(1,(8,4,4)),\n",
    "            nn.Unflatten(1,(1,64,64)),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3),\n",
    "\n",
    "           # nn.Linear(64,256),\n",
    "           # nn.Linear(256,256*256)\n",
    "        )\n",
    "        self.network1 = net1\n",
    "    \n",
    "    \n",
    "  def forward(self,x):\n",
    "        x = self.network1(x)\n",
    "    \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11af163f-205e-4351-8843-2c9dc7382b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1     [1, 4, 124, 124]             104             104\n",
      "            ReLU-2     [1, 4, 124, 124]               0               0\n",
      "       MaxPool2d-3       [1, 4, 62, 62]               0               0\n",
      "          Conv2d-4       [1, 4, 58, 58]             404             404\n",
      "          Conv2d-5       [1, 8, 54, 54]             808             808\n",
      "            ReLU-6       [1, 8, 54, 54]               0               0\n",
      "       MaxPool2d-7       [1, 8, 27, 27]               0               0\n",
      "          Conv2d-8       [1, 8, 23, 23]           1,608           1,608\n",
      "            ReLU-9       [1, 8, 23, 23]               0               0\n",
      "         Conv2d-10       [1, 8, 19, 19]           1,608           1,608\n",
      "           ReLU-11       [1, 8, 19, 19]               0               0\n",
      "        Flatten-12            [1, 2888]               0               0\n",
      "         Linear-13            [1, 6000]      17,334,000      17,334,000\n",
      "           ReLU-14            [1, 6000]               0               0\n",
      "         Linear-15           [1, 16384]      98,320,384      98,320,384\n",
      "      Unflatten-16     [1, 1, 128, 128]               0               0\n",
      "========================================================================\n",
      "Total params: 115,658,916\n",
      "Trainable params: 115,658,916\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "==================================== Hierarchical Summary ====================================\n",
      "\n",
      "customnet1(\n",
      "  (network1): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1)), 104 params\n",
      "    (1): ReLU(), 0 params\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 0 params\n",
      "    (3): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1)), 404 params\n",
      "    (4): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1)), 808 params\n",
      "    (5): ReLU(), 0 params\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), 0 params\n",
      "    (7): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1)), 1,608 params\n",
      "    (8): ReLU(), 0 params\n",
      "    (9): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1)), 1,608 params\n",
      "    (10): ReLU(), 0 params\n",
      "    (11): Flatten(start_dim=1, end_dim=-1), 0 params\n",
      "    (12): Linear(in_features=2888, out_features=6000, bias=True), 17,334,000 params\n",
      "    (13): ReLU(), 0 params\n",
      "    (14): Linear(in_features=6000, out_features=16384, bias=True), 98,320,384 params\n",
      "    (15): Unflatten(dim=1, unflattened_size=(1, 128, 128)), 0 params\n",
      "  ), 115,658,916 params\n",
      "), 115,658,916 params\n",
      "\n",
      "\n",
      "==============================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_model_summary as pms\n",
    "import torch\n",
    "from customnet1 import customnet1\n",
    "print(pms.summary(customnet1(), torch.zeros((1, 1, 128, 128)), show_input=False, show_hierarchical=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fecc5ed-16e3-4663-b09b-201c45cf2b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettest = Unet_FCLtest()\n",
    "input = torch.randn(1, 1, 256, 256)\n",
    "#input.cuda\n",
    "out = nettest.forward(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102c463-9c70-4d1a-9758-71fc3022e519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e9d70-93b1-4869-b140-aff564c6cc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965be79-98a4-4f5b-b172-c363c7445c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b910e4c-22ef-4002-8c73-4eb0b1f2fbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f3026-289a-41cf-801e-02da9b742cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63ced1-9d54-4eae-8eed-34e1a2fd99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(net1.encoder))#.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17a8e5-6f45-4545-881c-96c06c9ec5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(net1.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7b929-ab03-4dfb-8663-8d31f1335f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(net2.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227113c1-c84e-4bbb-a625-30f2a7c99b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Unet_FCL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c68b1b-c170-4f4f-b476-66c48d98c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604b616-d208-4791-aa16-df8b78c947a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0cab53-ecee-4e34-9451-f34b9ce7a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((x - y).abs().sum() for x, y in zip(net1.state_dict().values(), net2.state_dict().values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d91e0-8870-4c06-8f2b-6c263d6b9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(net2.state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406de7e-d0f0-4f95-a7c4-123a46820fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f809d-1761-41cd-9c43-e203302fbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                print('Mismtach found at', key_item_1[0])\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        print('Models match perfectly! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c27ae-e353-46d9-bc8f-75827dcdd8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                print('Mismtach found at', key_item_1[0])\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        print('Models match perfectly! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0047f5-18ee-4493-9863-90e52e6f5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(net1,net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef022c-dd37-494d-b0d3-11b26f3f1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 256, 256)\n",
    "#input.cuda\n",
    "out = net2.forward(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493944b8-ea3e-4075-bf15-79e9fa63976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net1(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d46c1e-6145-492f-9476-454d36f3a6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17924a9d-3353-42f0-90ab-ca35dde99911",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7437393-f4d2-44c5-bd7b-a102618f8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be86929-494a-41e3-98ea-2a7080f054f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
