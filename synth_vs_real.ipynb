{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644479c-386b-41b8-94d4-4ab3a1567254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "X\n",
      "Y\n",
      "Z\n",
      "intensity\n",
      "return_number\n",
      "number_of_returns\n",
      "scan_direction_flag\n",
      "edge_of_flight_line\n",
      "classification\n",
      "synthetic\n",
      "key_point\n",
      "withheld\n",
      "scan_angle_rank\n",
      "user_data\n",
      "point_source_id\n",
      "red\n",
      "green\n",
      "blue\n",
      "Normal_change_rate__0_01_\n",
      "Normal_change_rate__0_1_\n",
      "Roughness__0_1_\n",
      "Roughness__0_005786_\n",
      "DefectDepth\n",
      "ArcDist\n",
      "Int\n",
      "LocalZ\n",
      "Offset\n",
      "Chainage\n",
      "Coord__X\n",
      "Coord__Y\n",
      "Coord__Z\n",
      "number of points = 2061134\n",
      "52644996 84845996 1.6116630724029308\n",
      "number of pixels = 8247252\n",
      "width in pixels = 3646\n",
      "height in pixels = 2262\n",
      "mean pixel value = 571467.8801381681\n",
      "cropping masks\n",
      "cropping masks\n",
      "Unet\n",
      "resnet34\n",
      "cuda\n",
      "epoch: 0 training loss:  0.677   test loss:  0.624 \n",
      "epoch: 1 training loss:  0.597   test loss:  0.565 \n",
      "epoch: 2 training loss:  0.560   test loss:  0.506 \n",
      "epoch: 3 training loss:  0.548   test loss:  0.489 \n",
      "epoch: 4 training loss:  0.506   test loss:  0.465 \n",
      "epoch: 5 training loss:  0.485   test loss:  0.435 \n",
      "epoch: 6 training loss:  0.528   test loss:  0.414 \n",
      "epoch: 7 training loss:  0.466   test loss:  0.418 \n",
      "epoch: 8 training loss:  0.484   test loss:  0.421 \n",
      "epoch: 9 training loss:  0.472   test loss:  0.387 \n",
      "epoch: 10 training loss:  0.520   test loss:  0.430 \n",
      "epoch: 11 training loss:  0.481   test loss:  0.366 \n",
      "epoch: 12 training loss:  0.510   test loss:  0.407 \n",
      "epoch: 13 training loss:  0.487   test loss:  0.384 \n",
      "epoch: 14 training loss:  0.488   test loss:  0.403 \n",
      "epoch: 15 training loss:  0.493   test loss:  0.393 \n",
      "epoch: 16 training loss:  0.468   test loss:  0.366 \n",
      "epoch: 17 training loss:  0.503   test loss:  0.372 \n",
      "epoch: 18 training loss:  0.453   test loss:  0.360 \n",
      "epoch: 19 training loss:  0.446   test loss:  0.368 \n",
      "epoch: 20 training loss:  0.450   test loss:  0.349 \n",
      "epoch: 21 training loss:  0.533   test loss:  0.389 \n",
      "epoch: 22 training loss:  0.478   test loss:  0.369 \n",
      "epoch: 23 training loss:  0.498   test loss:  0.396 \n",
      "epoch: 24 training loss:  0.466   test loss:  0.352 \n",
      "epoch: 25 training loss:  0.477   test loss:  0.346 \n",
      "epoch: 26 training loss:  0.466   test loss:  0.347 \n",
      "epoch: 27 training loss:  0.453   test loss:  0.394 \n",
      "epoch: 28 training loss:  0.447   test loss:  0.351 \n",
      "epoch: 29 training loss:  0.423   test loss:  0.345 \n",
      "epoch: 30 training loss:  0.444   test loss:  0.331 \n",
      "epoch: 31 training loss:  0.458   test loss:  0.339 \n",
      "epoch: 32 training loss:  0.422   test loss:  0.358 \n",
      "epoch: 33 training loss:  0.479   test loss:  0.367 \n",
      "epoch: 34 training loss:  0.450   test loss:  0.320 \n",
      "epoch: 35 training loss:  0.441   test loss:  0.327 \n",
      "epoch: 36 training loss:  0.409   test loss:  0.349 \n",
      "epoch: 37 training loss:  0.440   test loss:  0.339 \n",
      "epoch: 38 training loss:  0.408   test loss:  0.320 \n",
      "epoch: 39 training loss:  0.458   test loss:  0.333 \n",
      "epoch: 40 training loss:  0.442   test loss:  0.322 \n",
      "epoch: 41 training loss:  0.443   test loss:  0.319 \n",
      "epoch: 42 training loss:  0.453   test loss:  0.307 \n",
      "epoch: 43 training loss:  0.427   test loss:  0.350 \n",
      "epoch: 44 training loss:  0.449   test loss:  0.309 \n",
      "epoch: 45 training loss:  0.449   test loss:  0.340 \n",
      "epoch: 46 training loss:  0.439   test loss:  0.327 \n",
      "epoch: 47 training loss:  0.469   test loss:  0.331 \n",
      "epoch: 48 training loss:  0.482   test loss:  0.343 \n",
      "epoch: 49 training loss:  0.466   test loss:  0.332 \n",
      "epoch: 50 training loss:  0.441   test loss:  0.331 \n",
      "epoch: 51 training loss:  0.472   test loss:  0.363 \n",
      "epoch: 52 training loss:  0.459   test loss:  0.346 \n",
      "epoch: 53 training loss:  0.429   test loss:  0.333 \n",
      "epoch: 54 training loss:  0.437   test loss:  0.319 \n",
      "epoch: 55 training loss:  0.435   test loss:  0.322 \n",
      "epoch: 56 training loss:  0.453   test loss:  0.334 \n",
      "epoch: 57 training loss:  0.461   test loss:  0.367 \n",
      "epoch: 58 training loss:  0.466   test loss:  0.335 \n",
      "epoch: 59 training loss:  0.453   test loss:  0.316 \n",
      "epoch: 60 training loss:  0.471   test loss:  0.333 \n",
      "epoch: 61 training loss:  0.438   test loss:  0.333 \n",
      "epoch: 62 training loss:  0.429   test loss:  0.319 \n",
      "epoch: 63 training loss:  0.461   test loss:  0.321 \n",
      "epoch: 64 training loss:  0.419   test loss:  0.319 \n",
      "epoch: 65 training loss:  0.433   test loss:  0.326 \n",
      "epoch: 66 training loss:  0.465   test loss:  0.319 \n",
      "epoch: 67 training loss:  0.432   test loss:  0.330 \n",
      "epoch: 68 training loss:  0.452   test loss:  0.336 \n"
     ]
    }
   ],
   "source": [
    "#test synthetic damagelevel vs real\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from UNETdice import unet\n",
    "from custommodel1 import custommodel1\n",
    "from raster import raster\n",
    "import os\n",
    "import shutil\n",
    "import albumentations as A\n",
    "from syntheticdamage import syntheticspall, syntheticflor\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from syntheticwall import syntheticwall\n",
    "import random\n",
    "from addnoise import addperlin1, addperlin2, addperlin3\n",
    "import os\n",
    "\n",
    "os.chdir(\"../data\")\n",
    "\n",
    "#path1 = 'C:/Users/eejmws/OneDrive - University of Leeds/Incoming data/'\n",
    "#path2 = 'C:/Users/jackm/OneDrive - University of Leeds/Incoming data/'\n",
    " \n",
    "#isdir1 = os.path.isdir(path1) \n",
    "#isdir2 = os.path.isdir(path2) \n",
    "\n",
    "#if isdir1 == True:\n",
    "#    os.chdir(path1)\n",
    "#elif isdir2 == True:\n",
    "#    os.chdir(path2)\n",
    "#else:\n",
    "#    print(\"directory not found\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "saveloc = ['18testsynth0/''18testsynth1/','18testsynth2/','18testsynth3/','18testsynth4/']#,'testideal4/','testideal5/']\n",
    "testmaskfile = \"testmask.tiff\"\n",
    "testfile = \"test.tiff\"\n",
    "#cloud =\"synthetic_defect_wall.tiff\"\n",
    "#maskfile = \"mask.png\"\n",
    "cloud =\"traincloud.las\"\n",
    "maskfile = \"mask.png\"\n",
    "#reslist = [0.7, 1, 1.5, 2, 3, 4]\n",
    "damagelist = [0.7]#, 0.55, 0.7, 0.75, 0.8]\n",
    "\n",
    "damagelevel = damagelist[0]\n",
    "\n",
    "testim = Image.open(\"test.tiff\")\n",
    "wallim = Image.open(\"wall.tiff\")\n",
    "\n",
    "\n",
    "\n",
    "res1 = 2\n",
    "dimlist = [512]\n",
    "dim1 = dimlist[0]\n",
    "synthproplist = [0,0.1,0.2, 0.5,1]\n",
    "table = [['Network', 'encoder', 'epochs', 'IOU', 'Precision', 'recall','dim']]\n",
    "#for dim1, saveloc in zip(dimlist,saveloc):\n",
    "variationmagnitude = 0.3\n",
    "x = 100\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"synth/\")\n",
    "except OSError:\n",
    "    pass \n",
    "\n",
    "\n",
    "\n",
    "for n in range(0,x):\n",
    "\n",
    "    t = 1\n",
    "#     while t == 1:\n",
    "\n",
    "#         try:\n",
    "#             blocklength = random.randint(50,350)\n",
    "#             blockheight = int(max(0.5,random.random())*blocklength/1.3)\n",
    "#             #create wall\n",
    "#             synthwall,synthmask = syntheticwall(int(wallim.size[0]/2),int(wallim.size[1]/2),blockheight,blocklength,\"syntheticwalltest\"+str(n)+\".tiff\")\n",
    "#             jointmask = synthmask\n",
    "#             #add spalling\n",
    "#             synthspalledwall3, spallmask = syntheticspall(synthwall,synthmask,damagelevel)\n",
    "#             #add efflorescence\n",
    "#             synthspalledwall2, flormask = syntheticflor(synthspalledwall3,synthmask,damagelevel)\n",
    "#             #surface variation\n",
    "#             synthspalledwall1, noiseadded = addperlin1(synthspalledwall2,variationmagnitude)\n",
    "#             #wall deformation\n",
    "#             synthspalledwall, deformationadded = addperlin2(synthspalledwall1,variationmagnitude)\n",
    "\n",
    "#             spalledwallim = Image.fromarray(synthspalledwall) \n",
    "#             spalledwallim.save(\"synth/\"+\"synthetic_defect_wall\"+str(n)+\".tiff\")\n",
    "#             jointmaskim = Image.fromarray(jointmask*255) \n",
    "#             jointmaskim.save(\"synth/\"+\"synthetic_defect_jointmask\"+str(n)+\".png\")\n",
    "#             spallmaskim = Image.fromarray(spallmask*255) \n",
    "#             spallmaskim.save(\"synth/\"+\"synthetic_defect_spallmask\"+str(n)+\".png\")\n",
    "#             flormaskim = Image.fromarray(flormask*255) \n",
    "#             flormaskim.save(\"synth/\"+\"synthetic_defect_efflorecencemask\"+str(n)+\".png\")\n",
    "#             noiseaddedim = Image.fromarray(noiseadded*255) \n",
    "#             noiseaddedim.save(\"synth/\"+\"synthetic_defect_noiseadded\"+str(n)+\".tiff\")\n",
    "#             deformationaddedim = Image.fromarray(deformationadded*255) \n",
    "#             deformationaddedim.save(\"synth/\"+\"synthetic_defect_deformationadded\"+str(n)+\".tiff\")\n",
    "#             t = 0\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for synthprop, saveloc in zip(synthproplist,saveloc):\n",
    "    \n",
    "   #  testim = Image.open(\"test.tiff\")\n",
    "   #  wallim = Image.open(\"wall.tiff\")\n",
    "   #  #maskim = Image.open(\"wall.tiff\")\n",
    "   #  wall = np.array(wallim)\n",
    "   #  #mask = np.array(maskim)\n",
    "   #  mask = wall>0.9\n",
    "   #  test = np.array(testim)\n",
    "   # #damagelevel = 0.7\n",
    "   #  spalledwall,spallingmask = syntheticspall(wall,mask,damagelevel)\n",
    "   #  spalledwallim = Image.fromarray(spalledwall) \n",
    "   #  spalledwallim.save(\"synthetic_defect_wall.tiff\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(saveloc)\n",
    "        os.makedirs(saveloc+\"results/\")\n",
    "        \n",
    "        os.makedirs(\"synth/\"+saveloc)\n",
    "        os.makedirs(\"synth/\"+saveloc+\"results/\")\n",
    "        \n",
    "    except OSError:\n",
    "        pass  \n",
    "    \n",
    "    \n",
    "    shutil.copyfile(testfile, saveloc+testfile)\n",
    "    shutil.copyfile(testmaskfile, saveloc+testmaskfile)\n",
    "    shutil.copyfile(cloud, saveloc+cloud)\n",
    "    shutil.copyfile(maskfile, saveloc+maskfile)\n",
    "    raster(cloud,saveloc,mask = 0,res=res1,dim=dim1) \n",
    "    raster(maskfile,saveloc,mask = 1,res=res1, dim = dim1)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    nosamples = len(os.listdir(saveloc+\"croppedimages/\"))\n",
    "    nosynthtoadd = int(nosamples*synthprop)\n",
    "    count = 0\n",
    "    nosynthadded = 1\n",
    "    while nosynthadded <=nosynthtoadd:\n",
    "        print(count)\n",
    "        \n",
    "        synthtoadd = \"synthetic_defect_wall\"+str(count)+\".tiff\"\n",
    "        masktoadd = \"synthetic_defect_jointmask\"+str(count)+\".png\"\n",
    "        # for filename in os.listdir(\"synth\"saveloc):\n",
    "        # filepath = os.path.join(dirpath, filename)\n",
    "        # try:\n",
    "        #     shutil.rmtree(filepath)\n",
    "        # except OSError:\n",
    "        #     os.remove(filepath)\n",
    "\n",
    "        try:\n",
    "            os.makedirs(\"synth/\"+saveloc+str(count)+\"/\")\n",
    "        except OSError:\n",
    "            pass\n",
    "        \n",
    "        raster(\"synth/\"+synthtoadd,\"synth/\"+saveloc+str(count)+\"/\",mask = 0,res=res1,dim=dim1)\n",
    "        raster(\"synth/\"+masktoadd,\"synth/\"+saveloc+str(count)+\"/\",mask = 1,res=res1, dim = dim1)\n",
    "        \n",
    "        nosynthsamples = len(os.listdir(\"synth/\"+saveloc+str(count)+\"/\"+\"croppedimages/\"))\n",
    "        \n",
    "        for a in range(1, nosynthsamples+1):\n",
    "            shutil.copyfile(\"synth/\"+saveloc+str(count)+\"/\"+\"croppedimages/\"+str(a)+\".tiff\", saveloc+\"croppedimages/\"+str(nosamples+nosynthadded)+\".tiff\")\n",
    "            shutil.copyfile(\"synth/\"+saveloc+str(count)+\"/\"+\"croppedmasks/\"+str(a)+\".tiff\", saveloc+\"croppedmasks/\"+str(nosamples+nosynthadded)+\".tiff\")\n",
    "\n",
    "            nosynthadded =nosynthadded + 1\n",
    "            \n",
    "        count = count+1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    encoderstotest = ['resnet34']\n",
    "    networkstotest = ['Unet']#,'UnetPlusPlus','DeepLabV3']\n",
    "    test = 1\n",
    "    n = 0\n",
    "    \n",
    "    \n",
    "    transparams = [\n",
    "       # A.RandomSizedCrop(min_max_height=(64, 512), height=512, width=512, w2h_ratio=1.0, interpolation=1, always_apply=False, p=0.75),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "       # A.RandomBrightnessContrast(p=0.7),\n",
    "        A.GaussNoise(always_apply=False, p=0.3, var_limit=(2, 8)),\n",
    "      #  A.RandomContrast(always_apply=False, p=0.3, limit=(-0.6, 0.6)),\n",
    "       # A.RandomRotate90(always_apply=False, p=0.75)\n",
    "       # A.CLAHE(p=1),\n",
    "        A.Emboss (alpha=(0.2, 0.5), strength=(0.1, 0.7), always_apply=False, p=0.2),\n",
    "       # A.RandomFog (fog_coef_lower=0.3, fog_coef_upper=1, alpha_coef=0.08, always_apply=False, p=1),\n",
    "       # A.RandomGamma (gamma_limit=(80, 120), eps=None, always_apply=False, p=1),\n",
    "       # A.RandomRain (slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1, drop_color=(200, 200, 200), blur_value=7, brightness_coefficient=0.7, rain_type=None, always_apply=False, p=1),\n",
    "        #A.Spatter (mean=0.65, std=0.3, gauss_sigma=2, cutout_threshold=0.68, intensity=0.6, mode='rain', color=None, always_apply=False, p=1),\n",
    "        #A.PiecewiseAffine (scale=(0.03, 0.05), nb_rows=4, nb_cols=4, interpolation=1, mask_interpolation=0, cval=0, cval_mask=0, mode='constant', absolute_scale=False, always_apply=False, keypoints_threshold=0.01, p=0.5)\n",
    "        A.ElasticTransform (alpha=1, sigma=50, alpha_affine=50, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, approximate=False, p=1),\n",
    "        \n",
    "    \n",
    "    \n",
    "    ]\n",
    "    transparamsv = [\n",
    "       # A.RandomSizedCrop(min_max_height=(64, 512), height=512, width=512, w2h_ratio=1.0, interpolation=1, always_apply=False, p=0.75),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "       # A.RandomBrightnessContrast(p=0.7),\n",
    "       # A.GaussNoise(always_apply=False, p=0.3, var_limit=(5, 5)),\n",
    "      #  A.RandomContrast(always_apply=False, p=0.3, limit=(-0.6, 0.6)),\n",
    "       # A.RandomRotate90(always_apply=False, p=0.75)\n",
    "       # A.CLAHE(p=1),\n",
    "\n",
    "    ]\n",
    "    \n",
    "    for network in networkstotest:\n",
    "        for encoder in encoderstotest:\n",
    "            pretrain = \"imagenet\"\n",
    "            if dim1 >= 512:\n",
    "                 batch = 2\n",
    "            else:\n",
    "                 batch = 4\n",
    "            path =saveloc\n",
    "            inno=1\n",
    "            nepochs = 300\n",
    "            print(network)\n",
    "            print(encoder)\n",
    "            #try:\n",
    "            #iou_score,precision,recall,epochsf = unet(test, inno, batch, path, nepochs, network, encoder, pretrain, dim1, transparams, transparamsv)\n",
    "            iou_score,precision,recall,epochsf = unet(test, inno, batch, path, nepochs, network, encoder, pretrain, dim1, transparams, transparamsv)\n",
    "\n",
    "            print(iou_score)\n",
    "            table.append([network, encoder, epochsf, iou_score, precision, recall, dim1])\n",
    "            #except:\n",
    "            print('training failed')#\n",
    "            \n",
    "print(tabulate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d0124-3889-46dc-a541-61cb78a96bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "saredgaswergsearg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d493fa-a0a2-47a9-adac-143441a61a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# INPUTS\n",
    "#inno = number of input channels\n",
    "#savestate = trained model to load in. format : 'test+\"/results/\"+savestate'\n",
    "#type1 = type of data used eg. depth, normal, RGB\n",
    "#network = type of network eg. Unet\n",
    "#test = path to data folder\n",
    "#encoder = name of encoder eg. mobilenet_v2\n",
    "#dim = dimension of image crops used in network. Images will be square. eg. dim = 512 will mean 512x512 patches. (note this code will autocrop input images into patches of the correct size)\n",
    "# testimage = name of testimage. Note, should be in root of data folder defined by 'test'\n",
    "# testmask = name of mask for testimage. Note, should be in root of data folder defined by 'test'\n",
    "\n",
    "# INPUT FILES\n",
    "# pytorch model at location: test+\"/results/\"+savestate\n",
    "# test image at location: test+testimage\n",
    "\n",
    "#OUTPUTS\n",
    "# iou_score = Intersection over union score for test image\n",
    "# precision = precisions score for test image\n",
    "# recall = recall score for test image\n",
    "\n",
    "# OUTPUT FILES\n",
    "# output of network on testimage after sigmoid function at location: test+'/results/picout{}{}{}{}.tiff'.format(type1,network,encoder,savetag)\n",
    "\n",
    "\n",
    "def UNETrun(inno, savestate, type1, network, test, encoder, dim, testimage, testmask, savetag):\n",
    "\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torchvision\n",
    "    from torch import nn, optim\n",
    "    from torchvision import datasets\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    from PIL import Image, ImageOps    \n",
    "    from torch.utils import data\n",
    "    import albumentations as A\n",
    "    import torchvision.utils as vutils\n",
    "    from torch.utils.data import Dataset as BaseDataset\n",
    "    import torchvision.transforms as transforms\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pathlib\n",
    "    from torch.autograd import Variable\n",
    "    import torch.nn.functional as F\n",
    "    from albumentations.pytorch import ToTensorV2    \n",
    "    import segmentation_models_pytorch as smp\n",
    "\n",
    "    Net = getattr(smp, network)(\n",
    "        encoder_name= encoder,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    " #   encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=inno,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=1,                      # model output channels (number of classes in your dataset)\n",
    "        ) \n",
    "\n",
    "    d = torch.load(test+\"/results/\"+savestate)\n",
    "    Net.load_state_dict(d[\"state_dict\"])\n",
    "\n",
    "   # Net.eval()\n",
    "    Net.cuda()\n",
    "    from PIL import Image\n",
    "   # if inno == 1:\n",
    "   #     pic = Image.open(test).convert('L')\n",
    "   # if inno == 3:\n",
    "   #     pic = Image.open(test).convert('RGB')\n",
    "    \n",
    "    pic = Image.open(test+testimage)\n",
    "\n",
    "    pic1 = pic.copy()\n",
    "    pic2 = pic.copy()\n",
    "    pic3 = pic.copy()\n",
    "    pic4 = pic.copy()\n",
    "   # dim = 512\n",
    "    w = pic.size[0]\n",
    "    nx = int(w/dim)\n",
    "    h = pic.size[1]\n",
    "    ny = int(h/dim)\n",
    "    i = 0\n",
    "    \n",
    "    picpastenp1 = np.zeros((w,h))\n",
    "    picpaste1 = Image.new(mode = 'F',size=(w,h)) \n",
    "    picpaste2 = Image.new(mode = 'F',size=(w,h))\n",
    "    picpaste3 = Image.new(mode = 'F',size=(w,h))\n",
    "    co_ords = np.zeros((2, nx*ny))\n",
    "\n",
    "    transformpil = transforms.ToPILImage()\n",
    "    size = 256\n",
    "\n",
    "    transform1 = A.Compose([\n",
    "           # A.PadIfNeeded(min_height=512, min_width=512, p=1),\n",
    "           # A.Resize(size,size),\n",
    "            ToTensorV2(),\n",
    "            ])    \n",
    "   \n",
    "    for x in range(0, nx+1):\n",
    "        for y in range(0,ny+1):\n",
    "          left = int(x*dim)\n",
    "          bottom = int(y*dim)\n",
    "          right =int(dim*(1+x))\n",
    "          top =int(dim*(1+y))\n",
    "          box = (left,bottom,right,top)\n",
    "          region = pic.crop(box)\n",
    "\n",
    "\n",
    "          if left< 0:\n",
    "\n",
    "            overlapleft = 0 - left\n",
    "            end = max(dim,(2*overlapleft))\n",
    "            copy = region.crop((overlapleft,0,end, dim))\n",
    "            width = copy.size[0]\n",
    "            mirrored = copy.transpose(0)\n",
    "            noverlap = int(overlapleft/width)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(end-width*(a+1),0,end-width*a,dim) )\n",
    "\n",
    "\n",
    "          if right> w:\n",
    "\n",
    "\n",
    "            overlapright = right - w\n",
    "            start = max(0,dim-(2*overlapright))\n",
    "            copy = region.crop((start,0,(dim-overlapright), dim))\n",
    "            width = copy.size[0]\n",
    "            mirrored = copy.transpose(0)\n",
    "            noverlap = int(overlapright/width)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(start+width*a,0,start+width*(1+a),dim) )\n",
    "\n",
    "\n",
    "\n",
    "          if bottom< 0:\n",
    "\n",
    "            overlapbottom = 0 - bottom\n",
    "            end = max(dim,(2*overlapbottom))\n",
    "            copy = region.crop((0,overlapbottom,dim,end))\n",
    "            height = copy.size[1]\n",
    "            mirrored = copy.transpose(1)\n",
    "            noverlap = int(overlapbottom/height)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(0,end-height*(a+1),dim,end-height*a) )\n",
    "\n",
    "          if top> h:\n",
    "\n",
    "            \n",
    "            overlaptop = top - h\n",
    "            start = max(0,dim-(2*overlaptop))\n",
    "            copy = region.crop((0,start,dim,(dim-overlaptop)))\n",
    "            height = copy.size[1]\n",
    "            mirrored = copy.transpose(1)\n",
    "            noverlap = int(overlaptop/height)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(0,start+height*a,dim,start+height*(1+a)) )\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "          with torch.no_grad():\n",
    "         \n",
    "                  imagepre = np.array(region)\n",
    "\n",
    "                  image = imagepre#.astype(np.uint8)\n",
    "\n",
    "                  transformed = transform1(image=image)\n",
    "                  image = transformed[\"image\"]\n",
    "\n",
    "                  img = image.float().cuda()\n",
    "                 \n",
    "                  img = torch.unsqueeze(img,0)\n",
    "                  pred = Net(img)\n",
    "\n",
    "                \n",
    "\n",
    "                  pred = pred.type(torch.FloatTensor)\n",
    "                  \n",
    "\n",
    "                \n",
    "                  out = pred.cpu().detach().numpy()\n",
    "                 # print(out[0][0].min())\n",
    "                  output = Image.fromarray(out[0][0])\n",
    "\n",
    "                \n",
    "                  outputf = output.resize((dim,dim))  \n",
    "                  \n",
    "               #   outputfnp = np.array(outputfnp)\n",
    "                    \n",
    "                  picpaste1.paste(outputf, box)  \n",
    "                  #pic1.paste(outputf, box)\n",
    "                #  t = np.array(pic1)\n",
    "                 # picpastenp1[]\n",
    "                 # print(outputf.mode)\n",
    "                 # print(t.min())\n",
    "                    \n",
    "                    \n",
    "                  #img = img.cpu().detach().numpy()  \n",
    "                  #plt.imshow(img[0][0], cmap='gray') \n",
    "                #  plt.imshow(out[0][0], cmap='gray') \n",
    "\n",
    "   # plt.imshow(pic1, cmap='gray') \n",
    "   # plt.imshow(picpaste1, cmap='gray') \n",
    "   # plt.imshow(pic1, cmap='gray') \n",
    "    offset = -dim/2\n",
    "    \n",
    "\n",
    "    nx2 = int((w-offset)/dim)\n",
    "    ny2 = int((h-offset)/dim)\n",
    "\n",
    "    for x in range(0, nx2+1):\n",
    "        for y in range(0,ny2+1):\n",
    "\n",
    "          left = int(x*dim+offset)\n",
    "          bottom = int(y*dim+offset)\n",
    "          right =int(dim*(1+x)+offset)\n",
    "          top =int(dim*(1+y)+offset)\n",
    "          box = (left,bottom,right,top)\n",
    "          region = pic.crop(box)\n",
    "\n",
    "\n",
    "          if left< 0:\n",
    "\n",
    "\n",
    "            overlapleft = 0 - left\n",
    "            end = max(dim,(2*overlapleft))\n",
    "            copy = region.crop((overlapleft,0,end, dim))\n",
    "            width = copy.size[0]\n",
    "            mirrored = copy.transpose(0)\n",
    "            noverlap = int(overlapleft/width)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(end-width*(a+1),0,end-width*a,dim) )\n",
    "\n",
    "\n",
    "          if right> w:\n",
    "\n",
    "\n",
    "            overlapright = right - w\n",
    "            start = max(0,dim-(2*overlapright))\n",
    "            copy = region.crop((start,0,(dim-overlapright), dim))\n",
    "            width = copy.size[0]\n",
    "            mirrored = copy.transpose(0)\n",
    "            noverlap = int(overlapright/width)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(start+width*a,0,start+width*(1+a),dim) )\n",
    "\n",
    "\n",
    "\n",
    "          if bottom< 0:\n",
    "\n",
    "            overlapbottom = 0 - bottom\n",
    "            end = max(dim,(2*overlapbottom))\n",
    "            copy = region.crop((0,overlapbottom,dim,end))\n",
    "            height = copy.size[1]\n",
    "            mirrored = copy.transpose(1)\n",
    "            noverlap = int(overlapbottom/height)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(0,end-height*(a+1),dim,end-height*a) )\n",
    "\n",
    "          if top> h:\n",
    "\n",
    "            overlaptop = top - h\n",
    "            start = max(0,dim-(2*overlaptop))\n",
    "            copy = region.crop((0,start,dim,(dim-overlaptop)))\n",
    "            height = copy.size[1]\n",
    "            mirrored = copy.transpose(1)\n",
    "            noverlap = int(overlaptop/height)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(0,start+height*a,dim,start+height*(1+a)) )        \n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "          with torch.no_grad():\n",
    "         \n",
    "                  imagepre = np.array(region)\n",
    "\n",
    "                  image = imagepre#.astype(np.uint8)\n",
    "\n",
    "                  transformed = transform1(image=image)\n",
    "                  image = transformed[\"image\"]\n",
    "\n",
    "                  img = image.float().cuda()\n",
    "                 \n",
    "                  img = torch.unsqueeze(img,0)\n",
    "                  pred = Net(img)\n",
    "\n",
    "                \n",
    "\n",
    "                  pred = pred.type(torch.FloatTensor)\n",
    "                  \n",
    "\n",
    "                \n",
    "                  out = pred.cpu().detach().numpy()\n",
    "                  output = Image.fromarray(out[0][0])\n",
    "\n",
    "                \n",
    "                  outputf = output.resize((dim,dim)) \n",
    "                  picpaste2.paste(outputf, box) \n",
    "                  #pic2.paste(outputf, box)\n",
    "\n",
    "    offset = int(-dim/5)\n",
    "\n",
    "\n",
    "    size = 256\n",
    "    nx3 = int((w-offset)/dim)\n",
    "    ny3 = int((h-offset)/dim)\n",
    "\n",
    "    for x in range(0, nx3+1):\n",
    "        for y in range(0,ny3+1):\n",
    "\n",
    "          left = int(x*dim+offset)\n",
    "          bottom = int(y*dim+offset)\n",
    "          right =int(dim*(1+x)+offset)\n",
    "          top =int(dim*(1+y)+offset)\n",
    "          box = (left,bottom,right,top)\n",
    "          region = pic.crop(box)\n",
    "\n",
    "\n",
    "          if left< 0:\n",
    "\n",
    "            overlapleft = 0 - left\n",
    "            end = min(dim,(2*overlapleft))\n",
    "            copy = region.crop((overlapleft,0,end, dim))\n",
    "            width = copy.size[0]\n",
    "            mirrored = copy.transpose(0)\n",
    "            noverlap = int(overlapleft/width)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(end-width*(a+1),0,end-width*a,dim) )\n",
    "\n",
    "\n",
    "          if right> w:\n",
    "\n",
    "\n",
    "            overlapright = right - w\n",
    "            start = max(0,dim-(2*overlapright))\n",
    "            copy = region.crop((start,0,(dim-overlapright), dim))\n",
    "            width = copy.size[0]\n",
    "            mirrored = copy.transpose(0)\n",
    "            noverlap = int(overlapright/width)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(start+width*a,0,start+width*(1+a),dim) )\n",
    "\n",
    "\n",
    "\n",
    "          if bottom< 0:\n",
    "\n",
    "            overlapbottom = 0 - bottom\n",
    "            end = min(dim,(2*overlapbottom))\n",
    "            copy = region.crop((0,overlapbottom,dim,end))\n",
    "            height = copy.size[1]\n",
    "            mirrored = copy.transpose(1)\n",
    "            noverlap = int(overlapbottom/height)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(0,end-height*(a+1),dim,end-height*a) )\n",
    "\n",
    "          if top> h:\n",
    "\n",
    "            overlaptop = top - h\n",
    "            start = max(0,dim-(2*overlaptop))\n",
    "            copy = region.crop((0,start,dim,(dim-overlaptop)))\n",
    "            height = copy.size[1]\n",
    "            mirrored = copy.transpose(1)\n",
    "            noverlap = int(overlaptop/height)\n",
    "            for a in range(1, noverlap+1):\n",
    "                region.paste(mirrored,(0,start+height*a,dim,start+height*(1+a)) )        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "          with torch.no_grad():\n",
    "         \n",
    "                  imagepre = np.array(region)\n",
    "\n",
    "                  image = imagepre#.astype(np.uint8)\n",
    "\n",
    "                  transformed = transform1(image=image)\n",
    "                  image = transformed[\"image\"]\n",
    "\n",
    "                  img = image.float().cuda()\n",
    "                 \n",
    "                  img = torch.unsqueeze(img,0)\n",
    "                  pred = Net(img)\n",
    "\n",
    "                \n",
    "\n",
    "                  pred = pred.type(torch.FloatTensor)\n",
    "                  \n",
    "\n",
    "                \n",
    "                  out = pred.cpu().detach().numpy()\n",
    "                  output = Image.fromarray(out[0][0])\n",
    "\n",
    "                \n",
    "                  outputf = output.resize((dim,dim))\n",
    "                  picpaste3.paste(outputf, box) \n",
    "                  #pic3.paste(outputf, box)\n",
    "    picnp = np.array(pic)\n",
    "    pic1np = np.array(picpaste1)\n",
    "    pic2np = np.array(picpaste2)\n",
    "    pic3np = np.array(picpaste3)\n",
    "    picavnp = pic1np/3+pic2np/3+pic3np/3\n",
    "    \n",
    "    #npclip = np.clip(pic6np,0,255)\n",
    "  #  original = Image.open(test)        \n",
    "\n",
    "\n",
    "\n",
    " #   originalnp =np.array(original)\n",
    "#    originalnormnp=(originalnp-originalnp.min())/(originalnp.max()-originalnp.min())\n",
    "    picnp = (picnp-picnp.min())/(picnp.max()-picnp.min())\n",
    "\n",
    "    \n",
    "    picoutnp = 1/(1+np.exp(-picavnp))\n",
    "    \n",
    "    #picoutnp = picnormavnp>0.5\n",
    "   # picoutnp2 = picavnpnorm>0.5\n",
    "    picout = Image.fromarray((picoutnp * 255).astype(np.uint8))\n",
    "    picout.save(test+'/results/picout{}{}{}{}.tiff'.format(type1,network,encoder,savetag))\n",
    "    im2 = picout \n",
    "    \n",
    "   # im = Image.open('test2/testmask.png')\n",
    "    #im2 = Image.open('test2/results/picout{}.png'.format(type1))\n",
    "    im2 = ImageOps.grayscale(im2)\n",
    "    prediction = np.array(im2)\n",
    "    \n",
    "    THRESHOLD = 125\n",
    "    prediction = prediction > THRESHOLD\n",
    "    prediction = prediction.astype(int)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(10, 20))\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    plt.imshow(picout)\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    plt.imshow(prediction)\n",
    "    ax1.title.set_text('output')\n",
    "    ax2.title.set_text('output binary')\n",
    "    \n",
    "    \n",
    "    \n",
    "    im = Image.open(test+testmask)\n",
    "    target = np.array(im)\n",
    "\n",
    "    \n",
    "    intersection = np.logical_and(target, prediction)\n",
    "    union = np.logical_or(target, prediction)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    width, height = im.size\n",
    "    nopix = width*height\n",
    "    predictionbin = np.logical_and(prediction, prediction)\n",
    "    targetbin = np.logical_and(target,target)\n",
    "    TP  = np.sum(intersection)\n",
    "    FP = np.sum(predictionbin)-TP\n",
    "    FN = np.sum(targetbin)-np.sum(intersection)\n",
    "    precision = TP/(TP+FP)\n",
    "    Recall = TP/(TP+FN)\n",
    "    print(\"IOU = {}\".format(iou_score))\n",
    "    print(\"precision = {}\".format(precision))\n",
    "    print(\"recall = {}\".format(Recall))\n",
    "    return iou_score,precision,Recall\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test on synthetic data\n",
    "#from RUN import UNETrun\n",
    "import os\n",
    "\n",
    "os.chdir(\"../data\")\n",
    "\n",
    "inno = 1 \n",
    "savestate = \"Final_epoch_21Unetmobilenet_v2.pt\"\n",
    "type1 = \"depth\"\n",
    "network = \"Unet\"\n",
    "test = \"testsynth2\"\n",
    "encoder = \"mobilenet_v2\"\n",
    "dim = 256\n",
    "testimage = \"/../synth/synthetic_defect_wall8.tiff\"\n",
    "testmask = \"/../synth/synthetic_defect_mask8.png\"\n",
    "\n",
    "iou_score,precision,recall =UNETrun(inno, savestate, type1, network, test, encoder, dim, testimage, testmask,\"synth8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd23244-463c-4603-bd6a-c15bac91d1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcb165-02c9-4456-9de2-68fbaf00fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437915f-70d3-4ecb-ac11-a424648f965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c1a13-e891-455f-a3d8-97128dcefe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "im = Image.open(\"../data/synth/synthetic_defect_wall2.tiff\")\n",
    "imnp = np.array(im)\n",
    "#im = cv.imread(\"synth/synthetic_defect_wall4.tiff\")\n",
    "plt.imshow(imnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f82b3-5518-4c44-9a9c-6102d77ecae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"../data/synth/synthetic_defect_mask2.png\")\n",
    "imnp = np.array(im)\n",
    "#im = cv.imread(\"synth/synthetic_defect_wall4.tiff\")\n",
    "plt.imshow(imnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3c614-f13a-4cc0-8ed5-83bdc73f531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"test.tiff\")\n",
    "imnp = np.array(im)\n",
    "im = cv.imread(\"synth/synthetic_defect_wall4.tiff\")\n",
    "plt.imshow(imnp, color = '-r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206b13a-9efd-451c-9134-96e6724015b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im = imread(\"C:/Users/eejmws/OneDrive - University of Leeds/Pytorch/data/testsynth2/croppedimages/83.tiff\")\n",
    "from skimage.io import imread\n",
    "im = imread(\"C:/Users/eejmws/OneDrive - University of Leeds/Pytorch/data/testsynth2/croppedimages/125.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61859c6-bfb8-4bb2-912b-c2c40104e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c954997-f132-49a0-9102-04b6290792ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917de9f1-3086-4c8e-a714-7c4ee779a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"C:/Users/eejmws/OneDrive - University of Leeds/Pytorch/data/testsynth2/croppedimages/86.tiff\")\n",
    "imnp = np.array(im)\n",
    "#im = cv.imread(\"synth/synthetic_defect_wall4.tiff\")\n",
    "plt.imshow(imnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbc0d6-8c48-4a85-b384-66ff62ba0b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
